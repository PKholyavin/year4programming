{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Наивный Байесовский классификатор\n",
    "\n",
    "\"Наивный\" &ndash; т.к. предполагает, что комбинируемые вероятности независимы.\n",
    "\n",
    "<!-- P(A|B) = P(B|A * P(A) / P(B) -->\n",
    "$$P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим, у нас есть набор документов, принадлежащих разным категориям.\n",
    "\n",
    "Попробуем определить вероятность того, что какой-то документ принадлежит категории, т.е. вероятность $P(категория|документ)$\n",
    "\n",
    "<!-- P(кат|док) = P(док|кат) * P(кат) / P(док) -->\n",
    "$$P(cat|doc) = \\frac{P(doc|cat) \\cdot P(cat)}{P(doc)}$$\n",
    "\n",
    "Оценим вероятность появления документа в данной категории $P(док|кат)$ как произведение вероятностей появления каждого слова в категории:\n",
    "\n",
    "<!-- P(док|кат) = П(P(слово|кат)) -->\n",
    "$$P(doc|cat) = \\prod_{word}{P(word|cat)}$$\n",
    "\n",
    "<!-- P(слово|кат) = C(слово, кат) / Σ(С(слово(i), кат)) -->\n",
    "$$P(word|cat) = \\frac{C(word, cat)}{L(cat)}$$\n",
    "\n",
    "где $L$ &ndash; длина категории в словах.\n",
    "\n",
    "Оценим $P(кат)$ как вероятность попадания случайно выбранного доумента в конкретную категорию.\n",
    "\n",
    "<!-- P(кат) = C(док, кат) / C(док) -->\n",
    "$$P(cat) = \\frac{C(doc, cat)}{C(doc)}$$\n",
    "\n",
    "$P(док)$ не зависит от категорий и для всех сравниваемых величин одинакова, поэтому можно её не учитывать. Тогда искомая категория:\n",
    "\n",
    "$$hypothesis = \\underset{cat}{\\text{arg max}}{\\prod_{word}{\\left( \\frac{ C(word, cat)}{L(cat)} \\right)} \\cdot \\frac{C(doc, cat)}{C(doc)}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Будет удобнее, если вы будете хранить вероятности не в прямом представлении, а в логарифмическом (основание логарифма может быть любым). Это позволяет:\n",
    "\n",
    "<details>\n",
    "    <summary></summary>\n",
    "\n",
    "    а) избежать underflow\n",
    "    б) заменить умножение на сложение\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Понятие стоп-слов: частотные слова, которые встречаются во всех категориях. Такие слова нужно убрать из текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'и в во не что он на я с со как а то все она так его но да ты к у же вы за бы по только ее мне было вот от меня еще нет о из ему теперь когда даже ну вдруг ли если уже или ни быть был него до вас нибудь опять уж вам ведь там потом себя ничего ей может они тут где есть надо ней для мы тебя их чем была сам чтоб без будто чего раз тоже себе под будет ж тогда кто этот того потому этого какой совсем ним здесь этом один почти мой тем чтобы нее сейчас были куда зачем всех никогда можно при наконец два об другой хоть после над больше тот через эти нас про всего них какая много разве три эту моя впрочем хорошо свою этой перед иногда лучше чуть том нельзя такой им более всегда конечно всю между'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\" \".join(stopwords.words(\"russian\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Иногда при делении на джва класса нам нужно иметь возможность сказать \"не знаю\". Тогда вычислим отношение между вероятностями принадлежности к двум категориям. Если оно меньше какого-то заданного порога, то однозначно принять решение нельзя."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Если в определяемом тексте нам встречается слово, которого не было ни в одной из категорий, мы можем его просто пропустить (оно не будет влиять на выбор категории). Если оно было только в одной категории, то мы можем в другой категории сделать вероятность этого слова или нулём (тогда все тексты с этим словом автоматически будут попадать в другую категорию), или специально заданным очень маленьким числом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Скорее всего, для такой классификации конкретные словоформы нам не очень важны. Поэтому воспользуемся pymorphy2 для определения исходной формы каждого слова."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Модуль pickle для сериализации (хранения) данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://pkholyavin.github.io/year4programming/conference_stud_clean.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"conference_stud_clean.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"new_pickle.pkl\", \"wb\") as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на список секций:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Антрополингвистика: Человек, Язык, Культура',\n",
       " 'Балканистика. Византинистика. Неоэллинистика',\n",
       " 'Балтистика',\n",
       " 'Библеистика',\n",
       " 'Будетляне. Гипотеза в филологии: TED TALKS',\n",
       " 'Будетляне. Гипотеза в филологии: научные бои',\n",
       " 'Будетляне. Гипотеза в филологии: научный слэм',\n",
       " 'Грамматика (романо-германская филология)',\n",
       " 'Грамматика и семантика русского языка',\n",
       " 'Дискурс и текст',\n",
       " 'История зарубежных литератур',\n",
       " 'История и диалектология русского языка',\n",
       " 'История и теория русского и западноевропейского стиха',\n",
       " 'История русского языка',\n",
       " 'Кино|Текст',\n",
       " 'Киноперевод',\n",
       " 'Классическая филология',\n",
       " 'Коллоквиалистика (анализ устной речи)',\n",
       " 'Компьютерная и прикладная лингвистика',\n",
       " 'Лексикология (романо-германская филология)',\n",
       " 'Лексикология и стилистика русского языка',\n",
       " 'Лингвометодические основы описания и изучения русского языка как иностранного',\n",
       " 'Литература в междисциплинарной перспективе',\n",
       " 'Междисциплинарная постерная сессия',\n",
       " 'Народная культура в древнем и новом слове',\n",
       " 'Общее языкознание',\n",
       " 'Переводоведение (романо-германская филология)',\n",
       " 'Пленарное заседание',\n",
       " 'Пленарное заседание 18 апреля',\n",
       " 'Пленарное заседание 19 апреля',\n",
       " 'Постерная сессия 18—22 апреля',\n",
       " 'Прикладная и математическая лингвистика',\n",
       " 'Психолингвистика',\n",
       " 'Русская литература: история',\n",
       " 'Русская литература: теория, поэтика',\n",
       " 'Славяно-германская компаративистика',\n",
       " 'Славянская филология: литературоведение',\n",
       " 'Славянская филология: языкознание',\n",
       " 'Славянская филология: языкознание и литературоведение',\n",
       " 'Театр',\n",
       " 'Финно-угорская филология',\n",
       " 'Фольклор и мифология',\n",
       " 'Фонетика'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set([i[\"section\"] for i in data])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание: обучить классификатор на корпусе текстов студенческой конференции (две разные секции или группы секций &ndash; например, литературоведение и лингвистика). Взять текст, не входящий в обучающую выборку, и попробовать определить его вероятность по каждой из двух моделей. Где вероятность больше, той секции, скорее всего, он и будет принадлежать.\n",
    "\n",
    "**1. Создать обучающие выборки**\n",
    "\n",
    "1.1. Отобрать тексты для каждой секции\n",
    "\n",
    "1.2. Каждый текст разбить на слова, произвести лемматизацию\n",
    "\n",
    "**2. Обучить классификатор**\n",
    "\n",
    "2.1. Для каждой категории вычислить $P(cat)$\n",
    "\n",
    "2.2. Составить список слов (лексикон)\n",
    "\n",
    "2.3. Для каждого слова и каждой категории вычислить $P(word|cat)$\n",
    "\n",
    "**3. Протестировать классификатор на тексте, не входящем в обучающую выборку**\n",
    "\n",
    "**4. Попробуйте построить систему не с двумя, а с тремя классами (или больше).**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
