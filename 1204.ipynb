{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наивный Байесовский классификатор\n",
    "\n",
    "\"Наивный\" - т.к. предполагает, что комбинируемые вероятности независимы.\n",
    "\n",
    "P(A|B) = P(B|A * P(A) / P(B)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим, у нас есть набор документов, принадлежащих разным категориям.\n",
    "\n",
    "Попробуем определить вероятность того, что какой-то документ принадлежит категории, т.е. вероятность P(категория|документ)\n",
    "\n",
    "P(кат|док) = P(док|кат) * P(кат) / P(док)\n",
    "\n",
    "Оценим вероятность появления документа в данной категории P(док|кат) как произведение вероятностей появления каждого слова в категории:\n",
    "\n",
    "P(док|кат) = П(P(слово|кат))\n",
    "\n",
    "Оценим P(кат) как вероятность попадания случайно выбранного доумента в конкретную категорию.\n",
    "\n",
    "P(кат) = C(док, кат) / C(док)\n",
    "\n",
    "P(док) не зависит от категорий и для всех сравниваемых величин одинакова, поэтому можно её не учитывать."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Понятие стоп-слов: частотные слова, которые встречаются во всех категориях. Такие слова нужно убрать из текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'и в во не что он на я с со как а то все она так его но да ты к у же вы за бы по только ее мне было вот от меня еще нет о из ему теперь когда даже ну вдруг ли если уже или ни быть был него до вас нибудь опять уж вам ведь там потом себя ничего ей может они тут где есть надо ней для мы тебя их чем была сам чтоб без будто чего раз тоже себе под будет ж тогда кто этот того потому этого какой совсем ним здесь этом один почти мой тем чтобы нее сейчас были куда зачем всех никогда можно при наконец два об другой хоть после над больше тот через эти нас про всего них какая много разве три эту моя впрочем хорошо свою этой перед иногда лучше чуть том нельзя такой им более всегда конечно всю между'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\" \".join(stopwords.words(\"russian\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Иногда при делении на джва класса нам нужно иметь возможность сказать \"не знаю\". Тогда вычислим отношение между вероятностями принадлежности к двум категориям. Если оно меньше какого-то заданного порога, то однозначно принять решение нельзя."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание: аналогично предыдущему, но с использованием наивного Байесовского классификатора."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
