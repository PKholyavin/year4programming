{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unl-IwH3qGX1"
      },
      "source": [
        "Токенизация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJhTlvoXrQ39"
      },
      "source": [
        "По каким признакам можно делить на предложения? Какие могут быть проблемы?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "It-ImWclqDId"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMfuwUlUqW4z"
      },
      "outputs": [],
      "source": [
        "text = 'Был тихий серый вечер. \"Кто это?\", спросил мальчик, заглядывая на следующую страницу.'\n",
        "\n",
        "sentences = nltk.tokenize.sent_tokenize(text, \"russian\")\n",
        "print(sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHryDM8zrYg7"
      },
      "source": [
        "Какие могут возникнуть проблемы при делении на слова?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcppdB7sq2WM"
      },
      "outputs": [],
      "source": [
        "for sent in sentences:\n",
        "  print(nltk.tokenize.word_tokenize(sent, \"russian\"))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sWwHisaFrelk"
      },
      "source": [
        "Задание:\n",
        "\n",
        "1. Взять любой текст (например, новостной или скачать с wikisource или lib.ru)\n",
        "\n",
        "Простое задание:\n",
        "\n",
        "2. С помощью nltk разбить текст на предложения, каждое предложение разбить на слова.\n",
        "3. Построить словари слов: алфавитный список, частотный список.\n",
        "\n",
        "Сложное задание:\n",
        "\n",
        "2. Самостоятельно реализовать алгоритм токенизации на предложения и слова.\n",
        "3. Построить словари слов: алфавитный список, частотный список.\n",
        "4. Найти слова, которые встретились по одному разу, выявить в них ошибки токенизации, предложить пути их исправления."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
