{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JVxQYY0zLjW"
      },
      "source": [
        "N-граммы - это языковые модели, которые используются для предсказания N-ного слова исходя из предыдущих N-1 слов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCC4EDWKzLja"
      },
      "source": [
        "P(w<sub>i</sub> | w<sub>i-N+1</sub>, w<sub>i-N+2</sub>, ..., w<sub>i-1</sub>) = C(w<sub>i-N+1</sub>, w<sub>i-N+2</sub>, ..., w<sub>i-1</sub>, w<sub>i</sub>) / C(w<sub>i-N+1</sub>, w<sub>i-N+2</sub>, ..., w<sub>i-1</sub>)  (1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdLJvcv53LoJ"
      },
      "source": [
        "Словами: вероятность встретить слово w<sub>i</sub> после слов w<sub>i-N+1</sub>, w<sub>i-N+2</sub>, ..., w<sub>i-1</sub> (назовём это историей) равна отношению количества раз, которое всё сочетание слов вместе с w<sub>i</sub> втретилось в обучающей выборки, к количеству раз, которое в выборке встретилась история."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwM8N1CNzLja"
      },
      "source": [
        "Пример: биграммы (N = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf8TUiA4zLjb"
      },
      "outputs": [],
      "source": [
        "corpus = \"John read her book. I read a different book. John read a book by Mulan.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srNaOQUEzLjc"
      },
      "source": [
        "Чтобы P(w<sub>i</sub> | w<sub>i-1</sub>) имело смысл для i = 1, добавим в начало каждого предложения специальный токен &lt;s&gt;. В общем случае таких токенов должно быть N - 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQ84eqyRzLjc"
      },
      "source": [
        "Чтобы вероятности всех последовательностей в сумме составляли 1, добавим в конец каждого предложения специальный токен &lt;/s&gt;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGHLQK8IzLjd"
      },
      "source": [
        "Теперь посчитаем вероятность P(John read a book):\n",
        "\n",
        "P(John read a book) = P(John | &lt;s&gt;) * P(read | John) * P(a | read) * P(book | a) * P(&lt;/s&gt; | book)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jI0SeLevzLjd"
      },
      "source": [
        "А какова вероятность P(Mulan read a book)?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aheU9pazLje"
      },
      "source": [
        "Сглаживание Лапласа: будем делать вид, что все возможные биграммы встретились на один раз больше, чем в реальности. Для этого в формуле (1) прибавим в числителе 1, а в знаменателе - размер словаря (включая &lt;s&gt; и &lt;/s&gt;):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6qMMkPCzLje"
      },
      "source": [
        "P(w<sub>i</sub> | w<sub>i-N+1</sub>, w<sub>i-N+2</sub>, ..., \n",
        "w<sub>i-1</sub>) = (C(w<sub>i-N+1</sub>, w<sub>i-N+2</sub>, ..., w<sub>i-1</sub>, w<sub>i</sub>) + 1) / (C(w<sub>i-N+1</sub>, w<sub>i-N+2</sub>, ..., w<sub>i-1</sub>) + V) (2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SP9pyJsxzLjf"
      },
      "source": [
        "Обработка неизвестных слов: добавим в словарь токен &lt;unk&gt;, на который будем заменять все незнакомые слова (которые не входят в словарь). Благодаря сглаживанию Лапласа для всех N-грамм с этим словом будут ненулевые вероятности."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kwdREbJzLjf"
      },
      "source": [
        "Задание: обучить две N-граммные модели на корпусе текстов студенческой конференции (две разные секции). Взять текст, не входящий в обучающую выборку, и попробовать определить его вероятность по каждой из двух моделей. Где вероятность больше, той секции, скорее всего, он и будет принадлежать.\n",
        "\n",
        "1. Создать обучающие выборки\n",
        "\n",
        "1.1. Отобрать тексты для каждой секции\n",
        "\n",
        "1.2. Каждый текст разбить на предложения, очистить от пунктуации, привести к нижнему регистру\n",
        "\n",
        "1.3. Каждое предложение разбить на слова, добавить &lt;s&gt; и &lt;/s&gt;, добавить в список предложений\n",
        "\n",
        "1.4. Должно получиться два списка предложений (по одному на каждую секцию). Каждое предложение - это список слов, первое из которых - &lt;s&gt;, а последнее - &lt;/s&gt;. Следите, чтобы не было пустых предложений.\n",
        "\n",
        "2. Обучить на каждой выборке N-граммную модель (N = 2 или 3)\n",
        "\n",
        "2.1. Для каждой выборки составить лексикон (т.е. список встретившихся слов)\n",
        "\n",
        "2.2. В лексикон должны входить &lt;s&gt;, &lt;/s&gt; и &lt;unk&gt;\n",
        "\n",
        "2.3. На основе лексикона составить список всех теоретически возможных N-грамм\n",
        "\n",
        "2.4. Для каждой N-граммы определить её вероятность по формуле (2)\n",
        "\n",
        "2.5. Записать эти вероятности в словарь\n",
        "\n",
        "2.6. Итого получилось два словаря, где ключи - N-граммы, значения - их вероятности. Эти словари и есть наши модели\n",
        "\n",
        "3. Использовать модель для определения принадлежности текста\n",
        "\n",
        "3.1. Взять текст, не входящий ни в одну из выборок (но желательно принадлежащий одной из двух секций)\n",
        "\n",
        "3.2. Очистить и разбить на предложения по алгоритму из п. 1.\n",
        "\n",
        "3.3. Для каждого предложения определить вероятность по каждой из двух моделей (не забывая заменять неизвестные модели слова на &lt;unk&gt;)\n",
        "\n",
        "3.4. Сделать выводы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FMLmlgq3LoP"
      },
      "source": [
        "Модуль pickle для сериализации (хранения) данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ethAXkxx5weW"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"conference_stud_2015.pkl\", \"rb\") as f:\n",
        "    data = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aCfXNWRn6dEk"
      },
      "outputs": [],
      "source": [
        "with open(\"new_pickle.pkl\", \"wb\") as f:\n",
        "    pickle.dump(data, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtlcWLTU3LoQ"
      },
      "source": [
        "Условный (!) пример обработки текста"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ki2VDFc6EL2",
        "outputId": "77cc94db-c9f8-4b55-96a4-083561b273af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['<s>', 'в', 'исследованиях', 'посвящённых', 'анализу', 'современного', 'состояния', 'русского', 'языка', 'в', 'качестве', 'одной', 'из', 'главных', 'тенденций', 'выделяется', 'тенденция', 'к', 'аналитизму', 'которая', 'проявляет', 'себя', 'в', 'увеличении', 'числа', 'слов', 'выражающих', 'грамматическое', 'значение', 'вне', 'словоформы', '</s>']\n",
            "['<s>', 'среди', 'явлений', 'выступающих', 'показателями', 'обозначенного', 'направления', 'учёные', 'особо', 'выделяют', 'пополнение', 'группы', 'аналитических', 'прилагательных', 'или', 'аналитов', 'единиц', 'агглютинативного', 'характера', 'являющихся', 'модификатором', 'производящей', 'базы', 'в', 'акте', 'словообразования', '</s>']\n",
            "['<s>', 'в', 'результате', 'увеличения', 'группы', 'аналитов', 'закономерным', 'становится', 'появление', 'в', 'языке', 'новых', 'словообразовательных', 'моделей', 'и', 'типов', '</s>']\n",
            "['<s>', 'в', 'центре', 'нашего', 'исследования', 'рассмотрение', 'одного', 'из', 'продуктивных', 'типов', 'в', 'котором', 'формантом', 'является', 'аналит-оним', '</s>']\n",
            "['<s>', 'особенность', 'имени', 'собственного', 'как', 'форманта', 'состоит', 'в', 'том', 'что', 'его', 'значение', 'автономно', 'более', 'конкретно', 'по', 'сравнению', 'с', 'обычными', 'морфемами', '</s>']\n",
            "['<s>', 'поэтому', 'для', 'полной', 'реализации', 'семантического', 'потенциала', 'заложенного', 'в', 'слове', 'требуется', 'контекст', 'горбачёв-фонд', 'фонд', 'президентом', 'которого', 'является', 'м', '</s>']\n",
            "['<s>', 'горбачёв', '</s>']\n",
            "['<s>', 'позиция', 'форманта', 'в', 'данном', 'словообразовательном', 'типе', 'строго', 'не', 'обозначена', '</s>']\n",
            "['<s>', 'при', 'общем', 'мотивационном', 'значении', 'организация', 'имеющая', 'отношение', 'к', 'указанному', 'имени', 'иили', 'общем', 'компоненте', 'она', 'может', 'быть', 'различна', 'арена-омск', 'минск-арена', '</s>']\n",
            "['<s>', 'однако', 'в', 'большинстве', 'случаев', 'преобладает', 'препозиция', 'что', 'можно', 'объяснить', 'соотнесением', 'указанных', 'словообразовательных', 'единиц', 'с', 'приставками', 'вследствие', 'агглютинативного', 'характера', 'последних', '</s>']\n",
            "['<s>', 'мода', 'на', 'использование', 'иностранных', 'языковых', 'моделей', 'также', 'объясняет', 'продуктивность', 'типа', '</s>']\n",
            "['<s>', 'влияние', 'иноязычных', 'наименований', 'особенно', 'отчётливо', 'прослеживается', 'на', 'примерах', 'организаций', 'которые', 'в', 'создании', 'и', 'ведении', 'дела', 'ориентируются', 'на', 'зарубежную', 'тематику', 'лондон', 'паб', 'паб', 'стилизованный', 'под', 'английское', 'заведение', '</s>']\n",
            "['<s>', 'на', 'это', 'указывает', 'и', 'сосуществование', 'в', 'языке', 'различных', 'форм', 'написания', '</s>']\n",
            "['<s>', 'одним', 'из', 'главных', 'преимуществ', 'использования', 'аналит-содержащих', 'единиц', 'является', 'экономия', 'языковых', 'средств', '</s>']\n",
            "['<s>', 'анализ', 'показывает', 'что', 'одинаковые', 'одноструктурные', 'слова', 'могут', 'иметь', 'и', 'раздельное', 'и', 'дефисное', 'написание', 'арена', 'омск', 'арена-омск', 'что', 'указывает', 'на', 'наш', 'взгляд', 'на', 'переходное', 'состояние', 'словообразующего', 'элемента', 'от', 'основы', 'к', 'аффиксу', '</s>']\n",
            "['<s>', 'причиной', 'данного', 'состояния', 'является', 'соотнесение', 'в', 'сознании', 'носителей', 'языка', 'имён', 'собственных', 'выступающих', 'в', 'качестве', 'префиксоида', 'с', 'их', 'регулярной', 'ролью', 'полнозначной', 'лексемы', '</s>']\n",
            "['<s>', 'опираясь', 'на', 'обозначенные', 'в', 'работе', 'факты', 'мы', 'приходим', 'к', 'выводу', 'что', 'данные', 'единицы', 'являются', 'полусложными', 'словами', 'с', 'аффиксоидом', 'аналитического', 'характера', '</s>']\n",
            "['<s>', 'таким', 'образом', 'расширение', 'группы', 'аналитических', 'прилагательных', 'и', 'как', 'следствие', 'увеличение', 'слов', 'содержащих', 'в', 'своей', 'структуре', 'аналит', 'в', 'частности', 'аналит-оним', 'ведёт', 'к', 'появлению', 'новых', 'словообразовательных', 'типов', 'на', 'фоне', 'общей', 'тенденции', 'к', 'аналитизму', 'в', 'системе', 'русского', 'языка', '</s>']\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "text = data[2][\"theses\"]\n",
        "text = re.sub(\"\\s+\", \" \", text).strip()\n",
        "text = text.lower()\n",
        "text = text.split(\".\")\n",
        "for sent in text:\n",
        "    sent = sent.strip()\n",
        "    if sent:\n",
        "        sent = re.sub(\"[^a-zа-яё0-9 -]\", \"\", sent)\n",
        "        print([\"<s>\"] + sent.split() + [\"</s>\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoG6T3-y3LoR"
      },
      "source": [
        "Отфильтруем данные только одной секции"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTt2g6493LoS"
      },
      "outputs": [],
      "source": [
        "phonetics_data = [i for i in data if i[\"section\"] == \"Фонетика\"]\n",
        "\n",
        "phonetics_corpus = []\n",
        "for entry in phonetics_data:\n",
        "    text = entry[\"theses\"]\n",
        "    # разбили на предложения\n",
        "    # убрали знаки препинания\n",
        "    # привели к нижнему регистру\n",
        "    # предложения разбили на слова\n",
        "    # добавили теги\n",
        "    sentences = []\n",
        "    phonetics_corpus += sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfqkDcgr3LoS"
      },
      "source": [
        "Посмотрим на список секций"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9U7VzFh68D7",
        "outputId": "e7c1f87d-4446-4928-ad59-82d4a269965c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Балканистика. Византинистика. Неоэллинистика',\n",
              " 'Библеистика',\n",
              " 'Будетляне. Гипотеза в филологии: TED TALKS',\n",
              " 'Грамматика (романо-германская филология)',\n",
              " 'Грамматика и семантика русского языка',\n",
              " 'История зарубежных литератур',\n",
              " 'История русского языка',\n",
              " 'Кино|Текст',\n",
              " 'Классическая филология',\n",
              " 'Лексикология (романо-германская филология)',\n",
              " 'Лексикология и стилистика русского языка',\n",
              " 'Лингвометодические основы описания и изучения русского языка как иностранного',\n",
              " 'Народная культура в древнем и новом слове',\n",
              " 'Общее языкознание',\n",
              " 'Переводоведение (романо-германская филология)',\n",
              " 'Пленарное заседание',\n",
              " 'Прикладная и математическая лингвистика',\n",
              " 'Психолингвистика',\n",
              " 'Русская литература: история',\n",
              " 'Русская литература: теория, поэтика',\n",
              " 'Славяно-германская компаративистика',\n",
              " 'Славянская филология: литературоведение',\n",
              " 'Славянская филология: языкознание',\n",
              " 'Финно-угорская филология',\n",
              " 'Фольклор и мифология',\n",
              " 'Фонетика'}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "set([i[\"section\"] for i in data])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CesMre893LoS"
      },
      "source": [
        "Функция enumerate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRhPOV5K8O7_",
        "outputId": "431da947-e0ae-4f5a-f72e-01e3843328b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 a\n",
            "1 b\n",
            "2 c\n",
            "3 d\n",
            "['aa', 'bb', 'cc', 'dd']\n"
          ]
        }
      ],
      "source": [
        "a = [\"a\", \"b\", \"c\", \"d\"]\n",
        "\n",
        "for i, el in enumerate(a):\n",
        "    print(i, el)\n",
        "    a[i] = el * 2\n",
        "\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyGjl7Fz3LoT"
      },
      "source": [
        "Функция itertools.product() для генерации N-грамм"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAkfrPaTGhun",
        "outputId": "6c9a1f80-7c29-48cf-ab53-f016f53bd0d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('a', 'a', 'a'), ('a', 'a', 'b'), ('a', 'a', 'c'), ('a', 'b', 'a'), ('a', 'b', 'b'), ('a', 'b', 'c'), ('a', 'c', 'a'), ('a', 'c', 'b'), ('a', 'c', 'c'), ('b', 'a', 'a'), ('b', 'a', 'b'), ('b', 'a', 'c'), ('b', 'b', 'a'), ('b', 'b', 'b'), ('b', 'b', 'c'), ('b', 'c', 'a'), ('b', 'c', 'b'), ('b', 'c', 'c'), ('c', 'a', 'a'), ('c', 'a', 'b'), ('c', 'a', 'c'), ('c', 'b', 'a'), ('c', 'b', 'b'), ('c', 'b', 'c'), ('c', 'c', 'a'), ('c', 'c', 'b'), ('c', 'c', 'c')]\n"
          ]
        }
      ],
      "source": [
        "from itertools import product\n",
        "\n",
        "words = [\"a\", \"b\", \"c\"]\n",
        "ngram_order = 3\n",
        "\n",
        "word_comb = product(words, repeat=ngram_order)\n",
        "print(list(word_comb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4VivAx13LoT"
      },
      "source": [
        "Обработка каждой N-граммы в предложении: сделаем списки N-грамм и N-1-грамм."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFsCVFpE3LoT",
        "outputId": "73f7aae4-23da-4b87-9bc8-9561a119a6be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('<s>', '<s>', 'a'), ('<s>', 'a', 'b'), ('a', 'b', 'c'), ('b', 'c', 'd'), ('c', 'd', 'e'), ('d', 'e', '</s>'), ('<s>', '<s>', 'a'), ('<s>', 'a', 'f'), ('a', 'f', 'd'), ('f', 'd', 'g'), ('d', 'g', 'n'), ('g', 'n', '</s>'), ('<s>', '<s>', 'e'), ('<s>', 'e', 'q'), ('e', 'q', 'y'), ('q', 'y', 'e'), ('y', 'e', '</s>')]\n",
            "[('<s>', '<s>'), ('<s>', 'a'), ('a', 'b'), ('b', 'c'), ('c', 'd'), ('d', 'e'), ('e', '</s>'), ('<s>', '<s>'), ('<s>', 'a'), ('a', 'f'), ('f', 'd'), ('d', 'g'), ('g', 'n'), ('n', '</s>'), ('<s>', '<s>'), ('<s>', 'e'), ('e', 'q'), ('q', 'y'), ('y', 'e'), ('e', '</s>')]\n"
          ]
        }
      ],
      "source": [
        "ngram_order = 3\n",
        "\n",
        "text = [[\"a\", \"b\", \"c\", \"d\", \"e\"], [\"a\", \"f\", \"d\", \"g\", \"n\"], [\"e\", \"q\", \"y\", \"e\"]]\n",
        "\n",
        "ngram_list = []\n",
        "ngram_part_list = []\n",
        "\n",
        "for sent in text:\n",
        "    sent = [\"<s>\"] * (ngram_order - 1) + sent + [\"</s>\"]\n",
        "    for i in range(len(sent) - ngram_order + 1):\n",
        "        ngram = sent[i:i + ngram_order]\n",
        "        ngram_list.append(tuple(ngram))\n",
        "    for i in range(len(sent) - ngram_order + 2):\n",
        "        ngram_part = sent[i:i + ngram_order - 1]\n",
        "        ngram_part_list.append(tuple(ngram_part))\n",
        "\n",
        "print(ngram_list)\n",
        "print(ngram_part_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посчитаем, сколько раз они встретились:"
      ],
      "metadata": {
        "id": "714buUZWC2x5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "ngram_counter = Counter(ngram_list)\n",
        "ngram_part_counter = Counter(ngram_part_list)"
      ],
      "metadata": {
        "id": "0hQzyT83_YJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Определим размер лексикона:"
      ],
      "metadata": {
        "id": "eN0lo6yZDBIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lexicon = sorted({w for sent in text for w in sent}) + [\"<s>\", \"</s>\", \"<unk>\"]\n",
        "V = len(lexicon)"
      ],
      "metadata": {
        "id": "qFU3W6LdDAkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посчитаем вероятность тестовой N-граммы по формуле (2):"
      ],
      "metadata": {
        "id": "SvpsojWGDGMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_ngram = (\"<s>\", \"<s>\", \"a\")\n",
        "hist = tuple(test_ngram[:-1])\n",
        "p = (ngram_counter.get(test_ngram, 0) + 1) / (ngram_part_counter.get(hist, 0) + V)\n",
        "print(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxdLRh2IDGCl",
        "outputId": "cfdf346d-b2fd-4e54-8499-e79b3a42c9f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1875\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}