{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исправление опечаток (спеллчекинг)\n",
    "\n",
    "Идея: если у нас есть словарь (список словоформ русского языка), мы можем попробовать определить, написано ли какое-то слово, введённое пользователем, с опечаткой или нет. Для этого нам нужно (1) определить, есть ли это слово в нашем словаре, и (2) если нет, то поискать в словаре слово, отличающееся от введённого не больше, чем на какое-то определённое небольшое расстояние Левенштейна (РЛ). Если нашлось, то предлагаем исправление; если не нашлось, делаем вывод, что это не опечатка, а просто неизвестное слово.\n",
    "\n",
    "Подход в лоб: посчитать расстояние Левенштейна между введённым словом и всеми словами в словаре, взять то, у которого расстояние минимальное. Минус подхода: будет работать очень долго, т.к. расстояние Левенштейна - \"дорогой\" алгоритм, а в словаре может быть много слов.\n",
    "\n",
    "Подход более умный (который надо реализовать):\n",
    "1. Если введённое слово есть в словаре, то всё хорошо, дальше можно не идти.\n",
    "2. Если нет, то для введённого слова сгенерируем все возможные русские слова/псевдослова, отстоящие от него на расстояние Левенштейна, равное 1. Для этого нужно провести все возможные элементарные операции: удаления (по одной удаляем из слова каждую букву), замены (по одной заменяем каждую букву в слове на каждую букву из русского алфавита), вставки (по одной вставляем каждую букву русского алфавита в каждую возможную позицию)\n",
    "\n",
    "Тогда для слова \"мама\" все возможные слова с РЛ=1:\n",
    "\n",
    "all_edits = [\"ама\", \"мма\", \"маа\", \"мам\", \"аама\", \"бама\", ..., \"мамю\", \"мамя\", \"амама\", \"бмама\", ..., \"маама\", \"мбама\", ..., \"мамаю\", \"мамая\"]\n",
    "\n",
    "3. Посмотрим, какие слова из этого списка есть в словаре.\n",
    "\n",
    "4. Если ни одного из этих слов нет в словаре, то тогда повторим пункт 2 для каждого слова из all_edits. Соединив результаты вместе, получим список слов, отстоящих от исходного на РЛ=2.\n",
    "\n",
    "5. Повторим пункт 3.\n",
    "\n",
    "6. Если и этих слов нет в словаре, делаем вывод, что опечатки нет, а просто слово неизвестно.\n",
    "\n",
    "7. В противном случае возвращаем список полученных слов, ранжированный по их частотности.\n",
    "\n",
    "---\n",
    "\n",
    "8. Если справитесь с пп. 1-7, постарайтесь улучшить программу так, чтобы она учитывала случайно вставленные или пропущенные пробелы.\n",
    "\n",
    "9. Если справитесь с п. 8, попробуйте изменить ранжирование вариантов так, чтобы сверху были самые вероятные опечатки. Для этого задайте функцию, которая определяет расстояние между двумя клавишами на клавиатуре. Например:  \n",
    "```\n",
    ">>>dist(\"ф\", \"ы\")\n",
    "1\n",
    ">>>dist(\"ф\", \"в\")\n",
    "2\n",
    "```  \n",
    "Детали имплементации на ваше усмотрение."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В файле fontanka_freqs.txt содержится частотный список словоформ русского языка. Числа справа от слов - их частотность в логарифмическом представлении. Чем больше число (по значению, а не по модулю), тем более частотное слово.\n",
    "\n",
    "Вопросы:  \n",
    "1. В чём преимущество хранения частотности (т.е. вероятности встретить слово) в логарифмическом представлении?\n",
    "2. Если нам нужно определить частотность сочетания двух слов (вероятность встретить два слова вместе), что нужно сделать? А в лог-представлении?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полезная информация: время поиска в списке гораздо больше, чем в словаре или множестве."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_set = {random.randint(1, 10 ** 9) for _ in range(10**7)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dict = {i: 0 for i in a_set}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_list = list(a_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "for t in range(100):\n",
    "    t in a_dict\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "for t in range(100):\n",
    "    t in a_set\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "for t in range(100):\n",
    "    t in a_list\n",
    "print(time.time() - start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
